# Chapter 3: Cluster Management
## High availability in K8s
K8s facilitates high availability for applications. but you can also provide k8s itself to be High available.
to do this, need mulitple control plane nodes.
### High availability in control plane
![k8s HA](https://github.com/hassj/CKA-acloudguru/blob/main/CKA-md/Image/HA-k8s.jpg "multiple control plane nodes")

when using multiple control plane nodes for HA. You will likely need to communicate with API through Load Balancer.

### Stacked etcd
![k8s Stacked etcd](https://github.com/hassj/CKA-acloudguru/blob/main/CKA-md/Image/stacked-etcd.jpg "Stacked etcd")
take a note that etcd residen within control plane node for each other kube-API

### External etcd
![k8s external etcd](https://github.com/hassj/CKA-acloudguru/blob/main/CKA-md/Image/external-etcd.jpg "external etcd")

## K8s management tools
- kubeadm: the tool for quickly and easily creating k8s cluster
- kubectl: official command line tools used to interact with k8s via kube-api
- minikube: the tools help you setting up single node k8s quickly and fit with development test purpose
- helm: provides templating and package management for k8s objects. it also manage your own template known as charts
- kompose: helps you translate docker compose file into k8s objects.
- kustomize: is a configuration management tool for managing k8s objects configuration. it allows you to share and re-use templated configuration for k8s apps.

## Safely draining node in K8s
- what is draining: somtimes you want to mantain the cluser. you need to remove the node from services. to do this, you can drain the node. and containers running on that node will be gracefully terminated (and pottentially rescheduled on another node)
- draining node

`kubectl drain <node_name>`
- ignoring daemonset: when draining node, you may need ignore daemonset ( pods running under daemonset will be tied to that node). so to get rid, you will liekly need to ignore the daemonset 

`kubectl drain <node_name> --ignore-daemonsets`

- uncordoning node: after maintenance if node still part of the cluster, you can allow pods to run again on that node.

`kubectl uncordon <node_name>`

## Upgrading k8s with kubeadm
### Upgrade steps control plane
- drain control plane node
- upgrade kubeadm on control plane
- Plan the upgrade control plane `` kubectl upgrade plan``
- apply the upgrade on control plane ``kubectl upgrade apply``
- uncordon the control plane nodes
- upgrade kubelete and kubectl on control plane nodes
```
kubectl drain k8s-control-node --ignore-daemonsets 
sudo apt-get update && sudo apt-get install -y --allow-change-held-packages kubeadm=1.27.2-00
sudo kubeadm upgrade plan v1.27.2			/ upgrade kubernetes internal components, this command will plan upgrading for components internal 
sudo kubeadm upgrade apply v1.27.2
sudo apt-get update && apt-get install -y --allow-change-held-packages kubelete=1.27.2-00 kubectl=1.27.2-00
sudo systemctl daemon-reload
sudo systemctl restart kubelete
sudo kubectl uncordon k8s-control-node	
```
> --allow-change-held-packages flag will keep the the kubeadm and kubectl package for update 

### Upgrade step worker node
- drain nodes
- upgrade kubeadm
- upgrade kubelete configuration ``kubeadm upgrade node ``
- upgrade kubelete and kubectl on worker nodes
- uncordon nodes

on the control-node
```
kubectl drain worker-node1 --ignore-daemonsets --force
```
on the worker-node
```
sudo apt-get update -y && apt-get install -y --allow-change-held-packages kubeadm=v1.27.2-00 
kubeadm upgrade node
sudo apt-get update && apt-get install -y --allow-change-held-packages kubelete=1.27.2-00 kubectl=1.27.2-00
sudo systemctl daemon-reload
sudo systemctl restart kubelete
```
on control-node
`kubectl uncordon worker-node1`

## Backing up and restore etcd 
- why back up etcd: etcd is backend storage database of k8s. it stores objects, applications metada also configurations of cluster. so backup cluster's data is backup etcd

- backing up etcd: using etcd command line tool ``etcdctl``

checking information of k8s cluster:
```
ETCDCTL_API=3 etcdctl get cluster.name \
--endpoint=https://<private_ip:2379 \
--cacert=/path_to/ca_authoiry_cert.pem \
--cert=/path_to/etcd_cert.pem \
--key=/path_to/etct_key.pem
```

after that keep backing up the etcd database
```
ETCDCTL_API=3 etcdctl snapshot save /location/store/backup_file.db \
--cacert=/path_to/ca_authoiry_cert.pem \
--cert=/path_to/etcd_cert.pem  \
--key=/path_to/etct_key.pem
```
- Remove ``/var/lib/etcd`` to simulate etcd crash

- restoring etcd
```
ETCDCTL_API=3 etcdctl snapshot restore /location/store/backup_file.db \
--initial-cluster etcd-restore=https://<private_ip>:2380 \
--initial-advertise-peer-urls https://<private_ip>:2380 \
--name etcd-restore \
--data-dir /var/lib/etcd
```
- Change permision and ownership for restored file of etcd
```
chown -R etcd:etcd /var/lib/etcd
systemctl restart etcd
```

